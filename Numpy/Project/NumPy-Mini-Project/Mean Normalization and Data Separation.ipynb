{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Normalization\n",
    "\n",
    "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is *normalized* in order to work correctly. The idea of normalization, also known as *feature scaling*, is to ensure that all the data is on a similar scale, *i.e.* that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1.\n",
    "\n",
    "In this lab, you will be performing a different kind of feature scaling known as *mean normalization*. Mean normalization will scale the data, but instead of making the values be between 0 and 1, it will distribute the values evenly in some small interval around zero. For example, if we have a dataset that has values between 0 and 5,000, after mean normalization the range of values will be distributed in some small range around 0, for example between -3 to 3. Because the range of values are distributed evenly around zero, this guarantees that the average (mean) of all elements will be zero. Therefore, when you perform *mean normalization* your data will not only be scaled but it will also have an average of zero. \n",
    "\n",
    "# To Do:\n",
    "\n",
    "You will start by importing NumPy and creating a rank 2 ndarray of random integers between 0 and 5,000 (inclusive) with 1000 rows and 20 columns. This array will simulate a dataset with a wide range of values. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of X is:  (1000, 20)\n"
     ]
    }
   ],
   "source": [
    "# import NumPy into Python\n",
    "import numpy as np\n",
    "\n",
    "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
    "X = np.random.randint(0,5001, size=(1000,20))\n",
    "\n",
    "# print the shape of X\n",
    "print('the shape of X is: ',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1093, 3832, 1683, ..., 4345, 2235, 1980],\n",
       "       [2492, 1211,  262, ..., 2531, 1385, 2821],\n",
       "       [4544, 1332, 1728, ..., 3356, 3703, 3752],\n",
       "       ...,\n",
       "       [4531,  869, 2229, ...,  473, 2389, 1928],\n",
       "       [ 797, 3320, 2754, ..., 3470, 3482, 1584],\n",
       "       [2386, 4072, 4898, ..., 1657, 4999, 1485]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you created the array we will mean normalize it. We will perform mean normalization using the following equation:\n",
    "\n",
    "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. In the space below, you will first calculate the average and standard deviation of each column of $X$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average of the values in each column of X\n",
    "ave_cols = np.average(X,axis=0)\n",
    "\n",
    "# Standard Deviation of the values in each column of X\n",
    "std_cols = np.std(X,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have done the above calculations correctly, then `ave_cols` and `std_cols`, should both be vectors with shape `(20,)` since $X$ has 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of ave_cols is:  (20,)\n",
      "the shape of std_cols is:  (20,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of ave_cols\n",
    "print('the shape of ave_cols is: ',ave_cols.shape)\n",
    "\n",
    "# Print the shape of std_cols\n",
    "print('the shape of std_cols is: ',std_cols.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now take advantage of Broadcasting to calculate the mean normalized version of $X$ in just one line of code using the equation above. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.98165974,  0.86522068, -0.55046438, ...,  1.27430093,\n",
       "        -0.20170274, -0.36511349],\n",
       "       [ 0.00372177, -0.91759085, -1.54400667, ...,  0.01038515,\n",
       "        -0.79833597,  0.20750301],\n",
       "       [ 1.44904189, -0.83528632, -0.51900104, ...,  0.58520903,\n",
       "         0.82871794,  0.84139833],\n",
       "       ...,\n",
       "       [ 1.43988538, -1.15022021, -0.16870921, ..., -1.42353914,\n",
       "        -0.09360684, -0.40051903],\n",
       "       [-1.19014646,  0.51695685,  0.19836306, ...,  0.66463924,\n",
       "         0.6735933 , -0.63474028],\n",
       "       [-0.07093902,  1.02846935,  1.69741631, ..., -0.59857978,\n",
       "         1.73840813, -0.70214698]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean normalize X\n",
    "X_norm = (X - ave_cols) / std_cols\n",
    "X_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have performed the mean normalization correctly, then the average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero, and they should be evenly distributed in some small interval around zero. You can verify this by filing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the average of all the values of X_norm 1.9895196601282805e-17\n",
      "the average of the minimum value in each column of X_norm -1.7268497776705982\n",
      "the average of he maximum value in each column of of X_norm 1.7406197210771925\n"
     ]
    }
   ],
   "source": [
    "# Print the average of all the values of X_norm\n",
    "print('the average of all the values of X_norm', np.mean(X_norm))\n",
    "\n",
    "# Print the average of the minimum value in each column of X_norm\n",
    "print('the average of the minimum value in each column of X_norm', np.mean(np.min(X_norm, axis=0)))\n",
    "\n",
    "# Print the average of the maximum value in each column of X_norm\n",
    "print('the average of he maximum value in each column of of X_norm', np.mean(np.max(X_norm, axis=0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should note that since $X$ was created using random integers, the above values will vary. \n",
    "\n",
    "# Data Separation\n",
    "\n",
    "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
    "\n",
    "1. A Training Set\n",
    "2. A Cross Validation Set\n",
    "3. A Test Set\n",
    "\n",
    "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. \n",
    "\n",
    "In this part of the lab you will separate `X_norm` into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of `X_norm` chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of `X_norm` are chosen and randomly distributed among the three new sets.\n",
    "\n",
    "You will start by creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this by using the `np.random.permutation()` function. The `np.random.permutation(N)` function creates a random permutation of integers from 0 to `N - 1`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 4, 1, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a random permutation of integers 0 to 4\n",
    "np.random.permutation(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "In the space below create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this in one line of code by extracting the number of rows of `X_norm` using the `shape` attribute and then passing it to the  `np.random.permutation()` function. Remember the `shape` attribute returns a tuple with two numbers in the form `(rows,columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[148 116 700 830 890 911 193  28 361 874 760 433 513  31 160 252 707 813\n",
      " 462  16  68 977 774 431 748 437 974 721  98 543 988 351 291 660 500 604\n",
      "   8 879  86 480 473 736 306 338 419 452  19  38 681 952 961 423  67 954\n",
      " 757 162 799 376 319 235 680 554 541 869 289 142 281  65 740  39 329 624\n",
      " 717 503 113 250 442 294 831 186 220  21 716 955 129 919 265 185 975  84\n",
      " 396 348 139 323 925 504 343   4 810 388 126  17 313 432 407 144 770 673\n",
      "  62  11   6 971 192 506 336  29 493 331 371  77 577 703 438 122  48 941\n",
      " 309  80   5 408 517 734 206 899 951 173 239 775 187 674 849 141 538 368\n",
      " 485 501 695 601 648 615 987 654 845 580 856 702 370 663 374 297 212 819\n",
      " 470  87 698 269 652 288 514 488 668 558 337 650 102 640 581 487 411 814\n",
      " 266 953 797 727 939 413 395 841 189 638 983  89 666  40 835 467  10 223\n",
      " 400 836 166 902 280 256  90 778 409 498 471 918 231  64 287 209 846 789\n",
      " 965  61 380 349 589 333 806  72 742 510 285 312 275 881 527 997 276 308\n",
      " 593 933 300 658 163 450  32 476 320 229 645 923 522 683 246 690 268 642\n",
      " 242 183 136 478 114 562 118 633 597 726 787 557 107 101 295 646 886 302\n",
      " 894 436 854 626 100 785 750 227  56 307 733 903 865  60 811 617 397 117\n",
      " 659 936 104  69 458 777 688 491 359 424 271  13 382 385 759 128 990 729\n",
      " 781 447 935 332 358 568 709 619 866 236 713 857 204 328 880 872 718 157\n",
      " 293 169  82  22 277 422 184 402 461 115 463 970 123 602 475 907 486   7\n",
      " 791 943 384 796 154  45 161 876 682 414 222 655  76 389 662 888 324 769\n",
      " 998 151 572 345 867 330 790 710 511 435 453 135 386 913 719 180 892 301\n",
      " 415  88 145 440 855 973 401 946 196 221 416 616 900 434 723 747 934 283\n",
      " 914 559 926  78 537 426 490 928 749 805 369 109 853 966 962 932 979 132\n",
      "  36 499 756 672 949 218 999 910 767 614 226 579 595 127 808 618 350 505\n",
      " 200 454 207 335 705 205 143 667 761 352 273 641 512 694 960 994 613 798\n",
      " 833 684 362 623  41 340 929 203 897 282 636 247 823  73 219 244 603 669\n",
      " 494 735 120 964 868 828 191 284 895 194 732 635 441 245 697 445 262 474\n",
      " 850 181  25 630 921 237 801 852 124 963 524 526 259 891 455 528 889   0\n",
      " 214  74 391 298 917 809 421 492 701 346 182  51 862  94 610 451 158 279\n",
      " 363 449  52 587 254 178 257 821 883 779 347 670 832 249 299 909 555 551\n",
      " 404 106 741 167 536 208 996 534 820 364 792 712 751 802 585 940 174 901\n",
      " 665 234 839 679 743 596 479 251 793 133 882 720 976 398 155 516 991  27\n",
      " 540 570 686 175 984 937 927 771 119 803 947 272 812 190 238 322 574 360\n",
      " 661 198 622 405 815 677 243 515 366 691 600 978 982 165 958 518 724  54\n",
      " 418  24 255 356  63 334 834 448 296 390  79 225 274 576  34  95  59 392\n",
      " 762 495 829 381 176 507 355 427 535 150 627 591 110 693 739 466 365 121\n",
      " 171 318 477 233 199 564 715  66 317 605 213 201 592 905 959  20 571  92\n",
      " 687 807 920 429 689 168 843  50 620 763  93 339 725 547 152   9 844 794\n",
      " 286   1  14 754 147 508 258 746 611 930 896 986 111 525 232 838 378 590\n",
      " 103 326  12 992 608 316 539 140 764 945 211 644 443 599 795 457 755   2\n",
      "  91 885 105  70 685 468 848 149 657 651  71 766 342 372 545 556 676 469\n",
      " 569  81 985  33 804  37 826 711 263 567 383 341 267 825  23 367 387 430\n",
      " 550 170 544 629 459 303 354 980 394 784 253 699 730 530  42 344 420 625\n",
      " 134 482 548 216 708 916 292 425 520 188 873 840 130 496 270 842 412 722\n",
      " 489 967 230 573 957 521 137 993 290 531 904  97 788 989 542 816 248 634\n",
      " 138 692 772 311 406 938 393 714 305 509 631  30 241 315 586 860 782 678\n",
      " 210 353 112 260 582 108 738 744  26  83 325 696 560 968 800 944 818  96\n",
      " 439 753 675  49 523 375 969 179 773 981 956 824 264 460 594 827 653  85\n",
      " 783 465 481 822 553 950 563 546 278 612 588 765 561 164 428 417 912 583\n",
      " 533 224 924 240 864 931 745 566 529 908 851 887 565 177 159 153 776 972\n",
      " 125 484 598 875 519  44 893 606 410 863 948 464 737 156 995 861 632  99\n",
      " 444  75 786 304 202 321 373 906 532  18  57 780 472 915 859 628 197 706\n",
      "  55 549 552 575 731 357 656 399 131 671 643 314 758 728  35 871 195   3\n",
      " 456 379 837 858  58 497  47 884 584 217 483 639 609 310 878 817 172 768\n",
      "  53 752 942 578 377 261 215 704 664  43 446 898 637  46 607 621 228 649\n",
      " 870 502 922 146 877 327 647  15 847 403]\n"
     ]
    }
   ],
   "source": [
    "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
    "row_indices = np.random.permutation(X_norm.shape[0])\n",
    "print(row_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create the three datasets using the `row_indices` ndarray to select the rows that will go into each dataset. Rememeber that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. Each set requires just one line of code to create. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make any necessary calculations.\n",
    "# You can save your calculations into variables to use later.\n",
    "training_idx, cross_val_idx, test_idx = row_indices[:600], row_indices[600:800], row_indices[800:]\n",
    "\n",
    "# Create a Training Set\n",
    "X_train = X_norm[training_idx,:]\n",
    "\n",
    "# Create a Cross Validation Set\n",
    "X_crossVal = X_norm[cross_val_idx,:]\n",
    "\n",
    "# Create a Test Set\n",
    "X_test = X_norm[test_idx,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you performed the above calculations correctly, then `X_tain` should have 600 rows and 20 columns, `X_crossVal` should have 200 rows and 20 columns, and `X_test` should have 200 rows and 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of X_train is:  (600, 20)\n",
      "the shape of X_crossVal is:  (200, 20)\n",
      "the shape of X_test is:  (200, 20)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of X_train\n",
    "print('the shape of X_train is: ',X_train.shape)\n",
    "\n",
    "# Print the shape of X_crossVal\n",
    "print('the shape of X_crossVal is: ',X_crossVal.shape)\n",
    "\n",
    "# Print the shape of X_test\n",
    "print('the shape of X_test is: ',X_test.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
