{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Normalization\n",
    "\n",
    "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is *normalized* in order to work correctly. The idea of normalization, also known as *feature scaling*, is to ensure that all the data is on a similar scale, *i.e.* that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1.\n",
    "\n",
    "In this lab, you will be performing a different kind of feature scaling known as *mean normalization*. Mean normalization will scale the data, but instead of making the values be between 0 and 1, it will distribute the values evenly in some small interval around zero. For example, if we have a dataset that has values between 0 and 5,000, after mean normalization the range of values will be distributed in some small range around 0, for example between -3 to 3. Because the range of values are distributed evenly around zero, this guarantees that the average (mean) of all elements will be zero. Therefore, when you perform *mean normalization* your data will not only be scaled but it will also have an average of zero. \n",
    "\n",
    "# To Do:\n",
    "\n",
    "You will start by importing NumPy and creating a rank 2 ndarray of random integers between 0 and 5,000 (inclusive) with 1000 rows and 20 columns. This array will simulate a dataset with a wide range of values. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of X is:  (1000, 20)\n"
     ]
    }
   ],
   "source": [
    "# import NumPy into Python\n",
    "import numpy as np\n",
    "\n",
    "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
    "X = np.random.randint(0,5001, size=(1000,20))\n",
    "\n",
    "# print the shape of X\n",
    "print('the shape of X is: ',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3104, 3423, 3208, ..., 1755, 4650, 4758],\n",
       "       [1868, 2553, 2129, ...,  345, 1847,  785],\n",
       "       [1817, 4109,  117, ..., 3847, 4405, 4319],\n",
       "       ...,\n",
       "       [1071, 3508, 2814, ..., 4171, 2118, 3445],\n",
       "       [2474,  615, 1591, ...,  151, 1460, 2994],\n",
       "       [2346, 4180, 1037, ..., 2579, 1576, 4442]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you created the array we will mean normalize it. We will perform mean normalization using the following equation:\n",
    "\n",
    "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. In the space below, you will first calculate the average and standard deviation of each column of $X$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average of the values in each column of X\n",
    "ave_cols = np.average(X,axis=0)\n",
    "\n",
    "# Standard Deviation of the values in each column of X\n",
    "std_cols = np.std(X,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have done the above calculations correctly, then `ave_cols` and `std_cols`, should both be vectors with shape `(20,)` since $X$ has 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of ave_cols is:  (20,)\n",
      "the shape of std_cols is:  (20,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of ave_cols\n",
    "print('the shape of ave_cols is: ',ave_cols.shape)\n",
    "\n",
    "# Print the shape of std_cols\n",
    "print('the shape of std_cols is: ',std_cols.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now take advantage of Broadcasting to calculate the mean normalized version of $X$ in just one line of code using the equation above. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.43283192,  0.66267568,  0.48586608, ..., -0.50151392,\n",
       "         1.44594713,  1.56114855],\n",
       "       [-0.40458863,  0.06984256, -0.2687668 , ..., -1.49247314,\n",
       "        -0.51634073, -1.19848554],\n",
       "       [-0.43914239,  1.130128  , -1.67592285, ...,  0.96876033,\n",
       "         1.27443071,  1.25622045],\n",
       "       ...,\n",
       "       [-0.94457582,  0.72059615,  0.21030968, ...,  1.19647011,\n",
       "        -0.32662257,  0.64914262],\n",
       "       [ 0.00599135, -1.25074433, -0.64503418, ..., -1.62881788,\n",
       "        -0.78726667,  0.33587935],\n",
       "       [-0.08073181,  1.17850863, -1.03249165, ...,  0.07759984,\n",
       "        -0.7060589 ,  1.34165589]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean normalize X\n",
    "X_norm = (X - ave_cols) / std_cols\n",
    "X_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have performed the mean normalization correctly, then the average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero, and they should be evenly distributed in some small interval around zero. You can verify this by filing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the average of all the values of X_norm 1.9184653865522706e-17\n",
      "the average of the minimum value in each column of X_norm -1.7213325466784817\n",
      "the average of he maximum value in each column of of X_norm 1.7311267259297634\n"
     ]
    }
   ],
   "source": [
    "# Print the average of all the values of X_norm\n",
    "print('the average of all the values of X_norm', np.mean(X_norm))\n",
    "\n",
    "# Print the average of the minimum value in each column of X_norm\n",
    "print('the average of the minimum value in each column of X_norm', np.mean(np.min(X_norm, axis=0)))\n",
    "\n",
    "# Print the average of the maximum value in each column of X_norm\n",
    "print('the average of he maximum value in each column of of X_norm', np.mean(np.max(X_norm, axis=0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should note that since $X$ was created using random integers, the above values will vary. \n",
    "\n",
    "# Data Separation\n",
    "\n",
    "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
    "\n",
    "1. A Training Set\n",
    "2. A Cross Validation Set\n",
    "3. A Test Set\n",
    "\n",
    "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. \n",
    "\n",
    "In this part of the lab you will separate `X_norm` into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of `X_norm` chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of `X_norm` are chosen and randomly distributed among the three new sets.\n",
    "\n",
    "You will start by creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this by using the `np.random.permutation()` function. The `np.random.permutation(N)` function creates a random permutation of integers from 0 to `N - 1`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 3, 2, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a random permutation of integers 0 to 4\n",
    "np.random.permutation(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "In the space below create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this in one line of code by extracting the number of rows of `X_norm` using the `shape` attribute and then passing it to the  `np.random.permutation()` function. Remember the `shape` attribute returns a tuple with two numbers in the form `(rows,columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 74 589 212 584 841  13 816 107 194 451 671 697 540 197 479 521 607  69\n",
      " 665 716 165 839 705 452 137 629 113 154 494  41 108 583 525 802 945 948\n",
      "  73 805 601 536 256 281 951 524 543 719  48 672 488 319 105 651 569 121\n",
      " 435  11 906 287 699 279 244 919 294 808 777 439  36 711 761 751 631  83\n",
      "  29 568 649 146 557 992 682 810 850 958 691 229 192 196 191 707 398 982\n",
      " 895 764 275 484  84 614  32 692 195 643 151 428 252  50 729 278 440 571\n",
      " 634 310 404 902 304 353   8 148 349 541 300 695 989 519 392 184 375 213\n",
      " 625 903  64 874 616 561 851 305 814   4 743 155  38 918 202 845 842 597\n",
      " 320 767  35   1 828 704 326 609 689 389 768 286 965  66 551 316  86 915\n",
      "  80  24 801 360 573 264 710 775 449 619 140 327 262 706 885 995 878 980\n",
      " 546 769 752 190 517 759 183 892 647 570 549 617 907 774 976 486 242 750\n",
      " 924 447 206 867 608  68 804 390 309 872 787 391 833 818 513 167 156 469\n",
      " 152 129 514 347 102 613  42 849 373 283 376 273  28 807 618 317 168 258\n",
      " 875  57 622 534   2 930 602 559 412  71 179 166 245 291 126 740 276 974\n",
      " 891 979 106 959 684 876 173 475 437 687 180 131 932 119 762 383 368 438\n",
      " 812 205 164 424  49 856 946 103 443 991  44 454 260 606  46 778 612 381\n",
      "  33 116  21  14 182 838 855  72 466 813 652 160 590 365 422  17 526 388\n",
      " 835 668 384 753 382 350 299 442 408 636 352 912 628 686 189  58 200 226\n",
      " 450 216 917 208 530 904 127 815 943 271 491 998 664 747 218 523 322 887\n",
      " 396 378  65 432 966 844 955 507 893 248 783 910 790 266 785 781 386 416\n",
      " 397 848 487 793 467 457 528  60 462 809 733 894 325 143 227  89 241 720\n",
      "  82 249 159 161 604 111 577 511 542 163 819 853 343 709 234 204 169 181\n",
      " 914 441 726  40 399 345 935 635 502  75 548   5 940 188 407 784 934 852\n",
      " 957 954 562 237 537 953 587 667 564 481 358 495 355 403 128 660 253 591\n",
      " 295 869 406 221 461 738 232 330 138 415 318 858 656 402 214 592 840  91\n",
      " 333 650 259 565 694 426 866 734 772 820 825 250 134 254 782 314 996 956\n",
      "  23  39 122 470 518 308 280 972 788  77 987 574 936 550 544 633  22 621\n",
      " 257  51 712 366 468 482 765 598  16 889 556  56 730 741 499 749 500 431\n",
      " 282 405 806 174 427 239  94 605 501 209   0 429 881 255 363 580 666 582\n",
      " 123 811 921 331 929 460 879 346 821 899 718  97 175 594 927 371 162 871\n",
      " 117 298 512 115  93 230 217 334 572 822 677 380 520 284 463 337 748  52\n",
      "   3 688  76 578 680 626 296  88 493 120 611 199 274 104 329 185 637 829\n",
      " 757 685 306 411 944 763 735 395 336 873 947 624 433 225 963 896 453 675\n",
      " 786 497 235 926 563 125 826 908 401 925 883 984 414 928 150 728 938 900\n",
      " 445 981  43 698 985 703 385 796 567 430 964 321 215 627 713 139 888 419\n",
      "  90 638 644 776 736 315 509 799 328 967 367  26 864 766 824 690 532 961\n",
      "  55 780  81 969 492 223 413 975 937 219 272 351  85 133 372  63 504 269\n",
      "  87 364 201  45 436 473 178 861 332 198 971 434 739 950 700 342 141 909\n",
      " 758 645 681   6 880 659 485  62 797 585 177 968 335 124 288 760 999 658\n",
      " 973 538 240 114 418 620 994  96 149 261 897 683 640 884  99 393 859 737\n",
      "  92 986 854 988 311 754   7 222 960 905 533 474 725 641 970 480 210 693\n",
      " 553 176 464 170 455 721 673 860 394 446 503  15 302 489 312 868 744 603\n",
      " 554 846  61 472 421 566 676 648  34 387 886  20 370 623 417 483 552  27\n",
      "  37 270 263 354 157 344 231 142 773 791 510 870 112 448 339 731 490  53\n",
      " 588 193 265 100 708 615  10 145 642 898 313 465 535 323 911 586 817 745\n",
      "  54 144 798 228 827 722 771 147 702 243 522 132 118 923 941  25 746  31\n",
      " 670 409 823 186 172 289 599 246 456 251 847 997 547 949 717 669 931 581\n",
      " 653  18 916 301  19 307 277 545 158 297 101 110 770  70 983 596 362 830\n",
      " 863 341 220 661 834 723 420 423 136 789 990 338 135 724 539 529  98  30\n",
      " 400 531 779 920 575 293 527 236 374 913 978 247 756 579 714 508 865 655\n",
      "  47 857 800 348 496 576 377 843 696 506 558 630 505 646 238 379 357 324\n",
      " 600 498 701 471 755 369 678 340 593 952 901 425 803 654 171 715 610 516\n",
      " 674 632 993 890 657 922  95 109 285 211 290 962 444 662 831  79 939 862\n",
      " 224   9 292 207 356 877 410 555 458 233 153  67 836 477 837 792  78 933\n",
      " 732 832 459 679 742 795 515 187  12 267 794 977 268 727 639 361 663  59\n",
      " 130 560 359 882 203 942 476 595 303 478]\n"
     ]
    }
   ],
   "source": [
    "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
    "row_indices = np.random.permutation(X_norm.shape[0])\n",
    "print(row_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create the three datasets using the `row_indices` ndarray to select the rows that will go into each dataset. Rememeber that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. Each set requires just one line of code to create. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-50-c396e3cf93ca>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-50-c396e3cf93ca>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    X_train = X_norm[]\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Make any necessary calculations.\n",
    "# You can save your calculations into variables to use later.\n",
    "training_idx, cross_val_idx, test_idx = row_indices[:600], row_indices[601:800], row_indices[801:]\n",
    "\n",
    "# Create a Training Set\n",
    "X_train = X_norm[training_idx,:]\n",
    "\n",
    "# Create a Cross Validation Set\n",
    "X_crossVal = X_norm[]\n",
    "\n",
    "# Create a Test Set\n",
    "X_test = X_norm[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you performed the above calculations correctly, then `X_tain` should have 600 rows and 20 columns, `X_crossVal` should have 200 rows and 20 columns, and `X_test` should have 200 rows and 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of X_train\n",
    "print('the shape of X_train is: ',X_train.shape)\n",
    "\n",
    "# Print the shape of X_crossVal\n",
    "print('the shape of X_crossVal is: ',X_crossVal.shape)\n",
    "\n",
    "# Print the shape of X_test\n",
    "print('the shape of X_test is: ',X_test.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
